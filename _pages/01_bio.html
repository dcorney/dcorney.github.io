---
layout: page
title: Who I am
permalink: /bio/
---
<h3>..and how I got here</h3>

I'm a research scientist and engineer: I enjoy discovering new knowledge and using it to solve real problems. I have a
strong interest in natural and artificial intelligence as applied to complex data. Since my PhD in machine learning,
I've carried out research and development in several areas including computational linguistics/NLP, visual neuroscience,
image processing, botanical taxonomy and online social networks and journalism. In each case, I have
helped to develop robust solutions to complex, data-centred problems.

<br><br>

After 10+ years as an academic researcher, I returned to the commercial sector in 2014 as a data scientist at <a
    href="http://www.signal.uk.com">Signal Media</a> (aka Signal AI). Here, we combined text analytics, machine learning
and business knowledge to automatically filter and rank millions of news articles every day. Our customers can track
news from their industry, monitoring risks and find opportunities, all without being overwhelmed by irrelevant data. I
later worked for another AI startup and a larger data science company, before joining <a href="fullfact.org">Full
    Fact<a></a> in 2019. Here, I work in the "automated fact checking" team, where I lead the use of machine learning
    and natural language processing to build tools to help fact checkers.

    <br><br>
    In April 2012, I joined the <a href="http://www.socialsensor.eu/">SocialSensor</a> project at <a
        href="http://www.city.ac.uk/informatics/research">City University London</a> as part of a team developing novel
    multimedia information retrieval systems. The focus is to find interesting news stories from online social networks
    --
    principally Twitter -- and to explain to the user why the stories are trending. We also want to help journalists to
    find
    eye-witnesses to events, such as by finding relevant images and videos. The team has since relocated to the <a
        href="http://www.rgu.ac.uk/research/research-institutes/institute-for-innovation-design-and-sustainability">Robert
        Gordon University</a>.
    <br><br>
    Before that, I worked as a research fellow at the University of Surrey, in the <a
        href="http://www.cs.surrey.ac.uk/">Department of Computing</a>. I developed software to analyse digital
    photographs
    of leaves, using specimens kindly provided by botanists at <a href="http://www.kew.org/">Kew Gardens</a> <a
        href="http://apps.kew.org/herbcat/gotoWhatIsHerbarium.do">herbarium</a>. The software analyses the shapes of
    leaves
    to aid identification and to allow further rigorous analysis. I used and enhanced geometric morphometric algorithms
    alongside more general image processing methods. One aim was to model relationships between leaf shape and climate,
    based on images of herbarium specimens.
    <br><br>
    Previously, I was a research fellow in the <a href="http://www.ucl.ac.uk/ioo">UCL Institute of Ophthalmology</a> as
    part
    of <a href="http://www.lottolab.org" target="_top">Beau Lotto's group</a>. I used various machine learning and
    statistical methods to investigate the human visual system. Why is it that we can see the world in such detail, with
    such robustness, and yet we still see optical illusions? These are not simply random errors of a imperfect
    instrument,
    but are systematic and consistent. They can tell us a lot about how the rest of the visual system works, and by
    extension, other modes of perception too. I developed a virtual visual ecology into which I could place "virtual
    animals". I let them adapt and evolve and learn to see, and then tested their perceptions and their internal
    workings.
    This model allowed me to investigate the perception of lightness, colour, depth and so on. Some of the work was
    described in this <A
        href="http://technology.newscientist.com/article/dn12701-artificial-brain-falls-for-optical-illusions.html">New
        Scientist</A> article.

    <br><br>
    Until 2006, I was working in the area of information extraction and text mining in the UCL Computer Science
    department
    (where I also did my PhD). I developed the BioRAT software, which performs information extraction from biological
    literature. I was in the <a href="http://bioinf.cs.ucl.ac.uk/" target="_top">Bioinformatics Group</a> at UCL and
    helped
    to organise <a href="http://bioinf.cs.ucl.ac.uk/bcb/biotext/">"BioText"</a>, a workshop held to discuss the
    application
    of text mining to the life sciences. I also explored the use of Google Maps then, using them to <a
        href="maps/PubMedMap.html">display publication rates of UK universities in the life sciences</a>. It provides a
    novel, visual interface to PubMed.
    <br><br>
    Along the way, I've also taught various aspects of computer science. Besides face-to-face teaching and supervision
    at
    several universities, I have supervised online computer science undergraduate projects at the University of
    Hertfordshire and taught various distance-learning modules at Queen Mary, University of London</a></a>>.