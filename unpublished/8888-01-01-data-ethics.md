---
layout: thought
category: thoughts
title: Data Feminism, bias detection
---

## Notes from the book "Data Feminism" and related sources  

I'm slowly reading Data Feminism, by Catherin D'Ignazio and Lauren Klein.

It's good - lots of it is eye-opening to me, as it shows data science from a perspective other than my own.

### Matrix of domination (p.15):

Four domains of domination

* *structural* Plans and policies
* *hegemonic* cultural
* *disciplinary* enforcement
* *interpersonal* invidival

### Priviledge hazard (p.28)

Ignorance due to being on top - it's easy to be unaware of ones own priviledge due to being priviledged.

### ML predicts the past not the future (p.55)

Data is never "raw" - it's always been selected, collected, filtered, cleaned, aggregated. The choice of what to measure is itself an expression of power - why does this data set exist, when that one doesn't? Which means once has to pay attention to what *doesn't* exist.

"Imagined objectivity" - the idea that data / algorithms are intrinsically objective.

## Other sources:

[ ] To read: Towards decolonising computational sciences
Abeba Birhane, Olivia Guest
https://arxiv.org/abs/2009.14258

[ ] to review: AI & algorithmic incident & controversy repository
https://docs.google.com/spreadsheets/d/1Bn55B4xz21-_Rgdr8BBb2lt0n_4rzLGxFADMlVW0PYI/edit#gid=177134770
Big & structured list of times when AI has "gone wrong" - 

[ ] to read: Government review into bias in algorithmic decision-making
https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/938857/Summary_Slide_Deck_-_CDEI_review_into_bias_in_algorithmic_decision-making.pdf
