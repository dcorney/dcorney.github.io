---
layout: post
category: thoughts
title: Bad information drives out good
---

More thoughts on GPT-3, ChatGPT and how the future of the web is looking bleaker by the day.

1. People running websites need a constant supply fresh web content to keep them at the [top of the search engine results](https://googleblog.blogspot.com/2011/11/giving-you-fresher-more-recent-search.html) and to keep their visitors coming back for more.

2. With GPT-3 and related models, generating fresh content has become a lot easier and cheaper: you no longer need to employ copy-writers when your algorithm can churn out reams of novel content for (approximately) no cost.

3. Determining whether claims in a piece of writing are true or not is an extra cost: it requires some kind of research or fact-checking, or at least some common sense. So inaccurate or unreliable content will always be cheaper to generate than accurate. For any model, "accuracy" is just one more constraint to satisfy, but only if we choose to include it[^1].

4. So the web is gradually filling up with unverified and inaccurate (but fresh! always fresh!) content. This applies to individual websites and to social media sites.
   
5. Finally, other people come along and scrape the fresh content to use as training data for the next-gen text-gen models. Some argue that we're already [running out of training data](https://www.technologyreview.com/2022/11/24/1063684/we-could-run-out-of-data-to-train-ai-language-programs/), so presumably new content will be much sought after.

The result? The average accuracy of web content will trend down. Inaccuracies will tend to drive out accuracies.

[Gresham's law](https://en.wikipedia.org/wiki/Gresham%27s_law) is usually written as "bad money drives out good". If two currencies have the same face value but one has greater intrinsic worth, then people will tend to hold on to it and therefore spend the currency with the lower commodity value. In the web-content case, consider two websites with the same face value (similar search engine ranking, similar user engagement). But one is written by humans and has a higher intrinsic worth, in that it is more reliable, but also costs more to produce. The other site is cheaper with lower-value content. But it is this bad information that will tend to proliferate, and GPT-3 will only accelerate the process.

Maybe search engines will start ranking sites by accuracy rather than freshness, but that sounds expensive and unlikely. I can't imagine any government legislating for accuracy, and besides the unintended consequences of such censorship would be horrendous.

<br>
<br>


----

[^1]: Even without automation, writing copy without checking facts is, and always has been, cheaper that writing quality content.