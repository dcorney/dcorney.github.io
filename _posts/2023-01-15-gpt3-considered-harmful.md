---
layout: post
category: thoughts
title: GPT3 considered harmful. 
---

There's been chatter recently about the potential harms that AI language-generating models, most famously GPT3 and ChatGPT, might lead to. This includes their [potential misuse in disinformation campaigns](https://openai.com/blog/forecasting-misuse/) and in automating [phishing scams](https://www.csoonline.com/article/3685368/study-shows-attackers-can-use-chatgpt-to-significantly-enhance-phishing-and-bec-scams.html). I recently considered if they could [help with automated fact checking](https://dcorney.com/thoughts/2022/12/09/inevitable-gpt3-post.html) -- they can't, of course. 

To date, I've not seen any actual harm caused by GPT3 or similar models, though I'm sure that'll come all too soon.
But a lot of these concerns would go away if a reliable detector could be built. An AI-generated-text detector could be used on social media platforms, email hosts and by search engine indexes to filter out (or at least clearly label) such content. It would then be no more concerning than spam is these days -- irritating, but fundamentally a solved problem.

Any attempts to [add watermarks to AI-generated text](https://www.newscientist.com/article/2350655-openai-is-developing-a-watermark-to-identify-work-from-its-gpt-text-ai/) will surely be bypassed quickly, such as by downstream paraphrasing to obscure any such identifiers.

I believe detecting the output of models like GPT3 is, and always will be, hard: the output doesn't look "machine generated" as we're used to in other fields -- it's not following fixed templates or repetitive patterns. The current generation of AI art-generators may not know how many fingers the human hand has[^1] but AI text generators have no problem with making sure nouns and verbs agree in number, for example. 

To make things harder, several businesses now sell AI language generators to help people write formal business emails or web content for SEO, including assisting people writing in their second language. And if we can't legitimately use AI tools to help us write, we'd better bin spell-checkers and grammar-checkers too. 

To me, the danger is that the content AI produces is not based on facts, but is nonetheless presented with great confidence[^2]. <i>And a lot of people also write like that.</i>  [Bullshit](https://press.princeton.edu/books/hardcover/9780691122946/on-bullshit) is [everywhere](https://www.bitebackpublishing.com/books/post-truth) and is part of being human. But it turns out you don't need to be human in order to bullshit. And that's a lesson we need to learn fast.




----
[^1]: It's four fingers and a thumb by the way - see? I'm not a robot!!
[^2]: The confidence is in the mind of the (human) reader: we tend to infer that someone is worth listening to if they're confident and don't use lots of hedging or hesitation. 
