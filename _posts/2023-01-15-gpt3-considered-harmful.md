---
layout: post
category: thoughts
title: GPT-3 considered harmful. 
---

There's been a lot of discussion recently about the potential harms that AI text-generation models, most famously GPT-3 and ChatGPT, might lead to. This includes their [misuse in running massive disinformation campaigns](https://openai.com/blog/forecasting-misuse/) and in automating [phishing scams](https://www.csoonline.com/article/3685368/study-shows-attackers-can-use-chatgpt-to-significantly-enhance-phishing-and-bec-scams.html). I recently considered if they could [help with automated fact checking](https://dcorney.com/thoughts/2022/12/09/inevitable-gpt3-post.html) -- they can't, of course. To date, I've not seen any actual harm caused by GPT-3 or similar models, though I'm sure that'll come all too soon.

A lot of these concerns would go away if a reliable detector could be built. An AI-generated-text detector could be used on social media platforms, email hosts and by search engine indexes to filter out (or at least clearly label) such content. It would then be no more concerning than spam is these days -- irritating, but fundamentally a solved problem.

I believe detecting the output of models like GPT-3 is, and always will be, hard: the output doesn't look "machine generated" as we're used to in other fields -- it's not following fixed templates or repetitive patterns. The current generation of AI art-generators may not know how many fingers the human hand has[^1] but AI text generators have no problem with making sure nouns and verbs agree in number, for example. And any attempts to [add watermarks to AI-generated text](https://www.newscientist.com/article/2350655-openai-is-developing-a-watermark-to-identify-work-from-its-gpt-text-ai/) will surely be bypassed quickly, such as by downstream paraphrasing to obscure any such identifiers.

To make things harder, several businesses now sell AI text-generators to help people write formal business emails or web content for SEO, including assisting people writing in their second language. And if we can't legitimately use AI tools to help us write, we'd better bin spell-checkers and grammar-checkers too. 

To me, the danger is that the content that AI produces is not based on facts, but is nonetheless presented with great confidence[^2]. <i>And a lot of people also write like that.</i>  [Bullshit](https://press.princeton.edu/books/hardcover/9780691122946/on-bullshit) is [everywhere](https://www.bitebackpublishing.com/books/post-truth) and is part of being human. But it turns out you don't need to be human in order to generate bullshit by the ton. And that's a lesson we need to learn fast.




----
[^1]: It's four fingers and a thumb by the way - see? I'm not a robot!!
[^2]: The confidence is in the mind of the (human) reader: we tend to assume that someone is worth listening to if they're confident, presumably as knowledge builds confidence, though this is a complicated field. 
